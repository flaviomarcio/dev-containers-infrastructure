version: '3'

networks:
  stack-nt:
    name: ${STACK_NETWORK_DEFAULT}
    external: true

services:
  pg:
    image: ${STACK_SERVICE_IMAGE_POSTGRES}
    volumes:
      - ${STACK_SERVICE_STORAGE_DATA_DIR}:/postgresql/pg/data
    environment:
      TZ: ${STACK_TZ}
      POSTGRES_USER: ${STACK_SERVICE_DEFAULT_USER}
      POSTGRES_PASSWORD: ${STACK_SERVICE_DEFAULT_PASS}
      PGDATA: /postgresql/pg/data

    healthcheck:
      test: ["CMD", "pg_isready", "-q", "-d", "${STACK_SERVICE_DEFAULT_DATABASE}", "-U", "${STACK_SERVICE_DEFAULT_USER}"]
      interval: 10s
      timeout: 5s
      retries: 3
    deploy:
      mode: global
      placement:
        constraints:
          - ${APPLICATION_DEPLOY_NODE_DB}
      resources:
          limits:
            cpus: "${APPLICATION_DEPLOY_CPU}"
            memory: ${APPLICATION_DEPLOY_MEMORY}
      restart_policy:
        condition: any
    networks:
      - stack-nt
  
  redis:
    image: docker.io/bitnami/redis:7.0
    # volumes:
    #   - ${STACK_SERVICE_STORAGE_DATA_DIR}:/bitnami/redis/data
    environment:
      TZ: ${STACK_TZ}
      ALLOW_EMPTY_PASSWORD: "yes"
    # ports:
    #   - '6379:6379'
    deploy:
      mode: global
      placement:
        constraints:
          - ${APPLICATION_DEPLOY_NODE_DB}
      resources:
          limits:
            cpus: "${APPLICATION_DEPLOY_CPU}"
            memory: ${APPLICATION_DEPLOY_MEMORY}
      restart_policy:
        condition: any
    networks:
      - stack-nt

  scheduler:
    image: docker.io/bitnami/airflow-scheduler:2
    environment:
      - AIRFLOW_DATABASE_NAME=${STACK_SERVICE_DEFAULT_DATABASE}
      - AIRFLOW_DATABASE_USERNAME=${STACK_SERVICE_DEFAULT_USER}
      - AIRFLOW_DATABASE_PASSWORD=${STACK_SERVICE_DEFAULT_PASS}
      - AIRFLOW_EXECUTOR=CeleryExecutor
      - AIRFLOW_WEBSERVER_HOST=airflow
    deploy:
      mode: global
      placement:
        constraints:
          - ${APPLICATION_DEPLOY_NODE_TOOL}
      resources:
          limits:
            cpus: "${APPLICATION_DEPLOY_CPU}"
            memory: ${APPLICATION_DEPLOY_MEMORY}
      restart_policy:
        condition: any
    networks:
      - stack-nt


  worker:
    image: docker.io/bitnami/airflow-worker:2
    environment:
      - AIRFLOW_DATABASE_NAME=${STACK_SERVICE_DEFAULT_DATABASE}
      - AIRFLOW_DATABASE_USERNAME=${STACK_SERVICE_DEFAULT_USER}
      - AIRFLOW_DATABASE_PASSWORD=${STACK_SERVICE_DEFAULT_PASS}
      - AIRFLOW_EXECUTOR=CeleryExecutor
      - AIRFLOW_WEBSERVER_HOST=airflow
    deploy:
      mode: global
      placement:
        constraints:
          - ${APPLICATION_DEPLOY_NODE_TOOL}
      resources:
          limits:
            cpus: "${APPLICATION_DEPLOY_CPU}"
            memory: ${APPLICATION_DEPLOY_MEMORY}
      restart_policy:
        condition: any
    networks:
      - stack-nt

  ui:
    image: docker.io/bitnami/airflow:2
    environment:
      - AIRFLOW_DATABASE_NAME=${STACK_SERVICE_DEFAULT_DATABASE}
      - AIRFLOW_DATABASE_USERNAME=${STACK_SERVICE_DEFAULT_USER}
      - AIRFLOW_DATABASE_PASSWORD=${STACK_SERVICE_DEFAULT_PASS}
      - AIRFLOW_EXECUTOR=CeleryExecutor
    # ports:
    #   - '8080:8080'
    deploy:
      mode: global
      placement:
        constraints:
          - ${APPLICATION_DEPLOY_NODE_TOOL}
      resources:
        limits:
          cpus: "${APPLICATION_DEPLOY_CPU}"
          memory: ${APPLICATION_DEPLOY_MEMORY}
      update_config:
        parallelism: 1
        delay: 10s
      restart_policy:
        condition: any
      labels:
        - traefik.docker.network=${STACK_NETWORK_DEFAULT}
        - traefik.http.routers.${STACK_SERVICE_NAME}.entryPoints=http,https
        - traefik.http.routers.${STACK_SERVICE_NAME}.tls=${STACK_TRAEFIK_TLS_ENABLED}
        - traefik.http.routers.${STACK_SERVICE_NAME}.rule=HostRegexp(`{subdomain:${STACK_SERVICE_HOSTNAME_PROXY}.*}`)
        - traefik.http.routers.${STACK_SERVICE_NAME}.service=${STACK_SERVICE_NAME}
        - traefik.http.services.${STACK_SERVICE_NAME}.loadbalancer.server.port=8080
    networks:
      - stack-nt