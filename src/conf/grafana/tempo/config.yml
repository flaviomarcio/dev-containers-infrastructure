target: all

#ref
#   https://github.com/grafana/tempo/blob/main/integration/e2e/config-metrics-generator.yaml

server:
  http_listen_port: 3200

query_frontend:
  search:
    query_backend_after: 0 # setting these both to 0 will force all range searches to hit the backend
    query_ingesters_until: 0

distributor:
  receivers:
    jaeger:
      protocols:
        grpc:
  log_received_spans:
    enabled: true

ingester:
  lifecycler:
    address: 127.0.0.1
    ring:
      kvstore:
        store: inmemory
      replication_factor: 1
    final_sleep: 0s
  trace_idle_period: 1s
  max_block_bytes: 1
  max_block_duration: 2s
  complete_block_timeout: 1s
  flush_check_period: 1s
  
compactor:
  compaction:
    block_retention: 1h                # overall Tempo trace retention. set for demo purposes

# metrics_generator:
#   registry:
#     external_labels:
#       source: tempo
#       cluster: docker-compose
#   storage:
#     path: /tmp/tempo/generator/wal
#     remote_write:
#       #- url: http://tempo_prometheus:9090/api/v1/write
#       - url: http://prometheus_srv:9090/api/v1/write
#         send_exemplars: true
# storage:
#   trace:
#     backend: local                     # backend configuration to use
#     wal:
#       path: /tmp/tempo/wal             # where to store the the wal locally
#     local:
#       path: /tmp/tempo/blocks


metrics_generator:
  processor:
    service_graphs:
      histogram_buckets: [1, 2]  # seconds
    span_metrics:
      histogram_buckets: [1, 2]  # seconds
  registry:
    collection_interval: 1s
  storage:
    path: /var/tempo
    remote_write:
      - url: http://${STACK_SERVICE_HOSTNAME_PROMETHEUS}:9090/api/v1/write
        send_exemplars: true


storage:
  trace:
    backend: local
    local:
      path: /var/tempo
    pool:
      max_workers: 10
      queue_depth: 100

overrides:
  metrics_generator_processors: [service-graphs, span-metrics] # enables metrics generator
  #max_traces_per_user: 50000
  max_traces_per_user: 1000